{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1427922,"sourceType":"datasetVersion","datasetId":836238},{"sourceId":8988058,"sourceType":"datasetVersion","datasetId":5413211}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U pip setuptools wheel\n!pip install -U spacy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-20T07:32:46.364279Z","iopub.execute_input":"2024-07-20T07:32:46.364952Z","iopub.status.idle":"2024-07-20T07:33:00.273476Z","shell.execute_reply.started":"2024-07-20T07:32:46.364915Z","shell.execute_reply":"2024-07-20T07:33:00.272351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:33:00.276259Z","iopub.execute_input":"2024-07-20T07:33:00.277191Z","iopub.status.idle":"2024-07-20T07:33:06.745011Z","shell.execute_reply.started":"2024-07-20T07:33:00.277140Z","shell.execute_reply":"2024-07-20T07:33:06.743924Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U gensim","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:33:06.746584Z","iopub.execute_input":"2024-07-20T07:33:06.746966Z","iopub.status.idle":"2024-07-20T07:33:15.790093Z","shell.execute_reply.started":"2024-07-20T07:33:06.746933Z","shell.execute_reply":"2024-07-20T07:33:15.788866Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport spacy\nimport random\n\nfrom gensim import models,corpora\nfrom gensim import similarities\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom wordcloud import WordCloud\n\nfrom spacy.lang.en import stop_words\nfrom gensim import corpora\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:34:22.913175Z","iopub.execute_input":"2024-07-20T07:34:22.913971Z","iopub.status.idle":"2024-07-20T07:34:47.207855Z","shell.execute_reply.started":"2024-07-20T07:34:22.913934Z","shell.execute_reply":"2024-07-20T07:34:47.206848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/cnn-articles-text-lda/cnn_articles.txt\",\"r\") as f:\n    articles=f.read().split(\"@delimiter\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Length of articles is: \",len(articles))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_i=random.sample(articles,1)\nrand_i","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=articles[:20000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm',disable=[\"parser\",\"ner\"])\nnlp.Defaults.stop_words.add(\"say\")\ndef basic_filter(tokenized_doc):\n    return [t.lemma_ for t in tokenized_doc if t.is_alpha and not t.is_punct and not t.is_space and t not in stop_words and t.pos_ in [\"NOUN\",\"VERB\",\"ADJ\"]]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:27.885674Z","iopub.execute_input":"2024-07-20T07:35:27.886616Z","iopub.status.idle":"2024-07-20T07:35:29.251136Z","shell.execute_reply.started":"2024-07-20T07:35:27.886580Z","shell.execute_reply":"2024-07-20T07:35:29.250141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_articles=list(map(basic_filter,nlp.pipe(dataset,n_process=4)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokenized_articles[5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TOPICS=20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndictionary=corpora.Dictionary(tokenized_articles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_token=\"news\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Id for \\'{sample_token}\\' token: {dictionary.token2id[sample_token]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncorpus_bow=[dictionary.doc2bow(article) for article in tokenized_articles]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(corpus_bow))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nldamodel=models.LdaModel(corpus=corpus_bow,\n                                num_topics=NUM_TOPICS,\n                                id2word=dictionary,\n                                random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ldamodel.print_topics()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dictionary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary.filter_extremes(no_below=5,no_above=0.6)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dictionary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_bow_w_pos_filtered=[dictionary.doc2bow(article) for article in tokenized_articles]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(corpus_bow_w_pos_filtered)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nldamodel=models.LdaModel(corpus=corpus_bow_w_pos_filtered,\n                        num_topics=NUM_TOPICS,\n                        id2word=dictionary,\n                        random_state=1,\n                        passes=10,\n                        eta=0.1,\n                        alpha=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ldamodel.print_topics()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ldamodel.eta)\nprint(ldamodel.alpha)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_articles_models(article_idx=10):\n    print(dataset[article_idx][:300])\n    print(\"--------------------------\\n\")\n    topics=sorted(ldamodel.get_document_topics(corpus_bow_w_pos_filtered[article_idx]),key=lambda tup:tup[1])[::-1]\n    return topics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topics=show_articles_models(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for pair in topics:\n    print(sorted(ldamodel.show_topic(pair[0]),key=lambda tup:tup[1])[::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topics=show_articles_models(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ldamodel.show_topic(topics[2][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_topics(article_idx,min_topic_prob):\n    topic_prob_pairs=sorted(ldamodel.get_document_topics(corpus_bow_w_pos_filtered[article_idx],\n                                                         minimum_probability=min_topic_prob),\n                            key=lambda tup:tup[1])[::-1]\n    word_prob_pairs=[ldamodel.show_topic(pair[0]) for pair in topic_prob_pairs]\n    \n    topic_words=[[pair[0] for pair in collection] for collection in word_prob_pairs]\n    data={\n        \"Major Topics\":topic_prob_pairs,\n        \"Topic Words\":topic_words\n    }\n    return pd.DataFrame(data)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"max_colwidth\",600)\nsnippet_length=300\nmin_topic_prob=0.30\narticle_idx=1\nprint(dataset[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_idx=10\nprint(dataset[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_idx=1000\nprint(dataset[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_idx=10000\nprint(dataset[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyLDAvis.gensim\npyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(ldamodel, corpus_bow_w_pos_filtered, dictionary)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:32:19.578402Z","iopub.status.idle":"2024-07-20T07:32:19.578945Z","shell.execute_reply.started":"2024-07-20T07:32:19.578663Z","shell.execute_reply":"2024-07-20T07:32:19.578684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs(\"file\",exist_ok=True)\ndef render_word_cloud(model,rows,cols,max_words):\n    word_cloud=WordCloud(background_color=\"white\",max_words=max_words,prefer_horizontal=1.0)\n    fig,axes=plt.subplots(rows,cols,figsize=(15,15))\n    \n    for i ,ax in enumerate(axes.flatten()):\n        fig.add_subplot(ax)\n        topic_words=dict(model.show_topic(i))\n        word_cloud.generate_from_frequencies(topic_words)\n        plt.gca().imshow(word_cloud,interpolation=\"bilinear\")\n        plt.gca().set_title(\"Topic {id}\".format(id=i))\n        plt.gca().axis(\"off\")\n    plt.axis(\"off\")\n    plt.savefig(\"file/WordCloud.jpg\")\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"render_word_cloud(ldamodel,3,3,10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_index=similarities.MatrixSimilarity(ldamodel[corpus_bow_w_pos_filtered],num_features=len(dictionary))\ndef get_similar_articles(index, model, article_bow, top_n=5, first_m_words=300):\n    \n\n      similar_docs = index[model[article_bow]]\n      top_n_docs = sorted(enumerate(similar_docs), key=lambda item: -item[1])[1:top_n+1]\n  \n      return list(map(lambda entry: (entry[0], entry[1], articles[entry[0]][:first_m_words]), top_n_docs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncoherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized_articles, dictionary=dictionary, coherence='u_mass')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_index=0\nprint(dataset[article_index][:snippet_length],\"\\n\")\nget_similar_articles(lda_index,ldamodel,corpus_bow_w_pos_filtered[article_idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_index=100\nprint(dataset[article_index][:snippet_length],\"\\n\")\nget_similar_articles(lda_index,ldamodel,corpus_bow_w_pos_filtered[article_idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_article = \"Capricorn Business Acquisitions Inc. (TSXV: CAK.H) (the “Company“)  is pleased to announce that its board has approved the issuance of 70,000 stock options (“Stock Options“) to directors on April 19, 2020.\"\narticle_tokens=list(map(basic_filter,[nlp(test_article)]))[0]\narticle_bow=dictionary.doc2bow(article_tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_similar_articles(lda_index,ldamodel,article_bow)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_article = \"DEA agent sentenced to 12 years in prison for conspiring with Colombian drug cartel.\"\narticle_tokens=list(map(basic_filter,[nlp(test_article)]))[0]\narticle_bow=dictionary.doc2bow(article_tokens)\nget_similar_articles(lda_index,ldamodel,article_bow)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_perplexity(corpus_bow_w_pos_filtered, dictionary, num_topics_list):\n    perplexities = []\n    for num_topics in num_topics_list:\n        lda_model = models.LdaModel(corpus=corpus_bow_w_pos_filtered,\n                        num_topics=num_topics,\n                        id2word=dictionary,\n                        random_state=1,\n                        passes=10,\n                        eta=0.1,\n                        alpha=0.1)\n        perplexity = lda_model.log_perplexity(corpus_bow_w_pos_filtered)\n        perplexities.append(perplexity)\n        print(f'Number of topics: {num_topics}, Perplexity: {perplexity}')\n    return perplexities\n\n# Example usage\nnum_topics_list = [5, 10, 15, 20, 25]\nperplexities = evaluate_perplexity(corpus_bow_w_pos_filtered, dictionary, num_topics_list)\nbest_num_topics = num_topics_list[np.argmin(perplexities)]\nprint(f'Best number of topics based on perplexity: {best_num_topics}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models.coherencemodel import CoherenceModel\n\ndef evaluate_topic_models(corpus_bow_w_pos_filtered, dictionary, num_topics_list):\n    coherence_scores = []\n    for num_topics in num_topics_list:\n        lda_model = models.LdaModel(corpus_bow_w_pos_filtered, num_topics=num_topics, id2word=dictionary, passes=15)\n        coherence_model = CoherenceModel(model=lda_model, texts=tokenized_articles, dictionary=dictionary, coherence='c_v')\n        coherence_score = coherence_model.get_coherence()\n        coherence_scores.append(coherence_score)\n        print(f'Number of topics: {num_topics}, Coherence Score: {coherence_score}')\n    return coherence_scores\n\nnum_topics_list = [5, 10, 15, 20, 25]\ncoherence_scores = evaluate_topic_models(corpus_bow_w_pos_filtered, dictionary, num_topics_list)\nbest_num_topics = num_topics_list[np.argmax(coherence_scores)]\nprint(f'Best number of topics: {best_num_topics}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import HdpModel\n\n\nhdp_model = HdpModel(corpus_bow_w_pos_filtered, id2word=dictionary)\n\nfor topic_id, topic in hdp_model.show_topics(formatted=False):\n    print(f\"Topic {topic_id}:\")\n    print(\" \".join([word for word, _ in topic]))\n    \n\ncoherence_model = CoherenceModel(model=hdp_model, texts=tokenized_articles, dictionary=dictionary, coherence='c_v')\ncoherence_score = coherence_model.get_coherence()\nprint(f'Coherence Score: {coherence_score}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_coherence_score(NUM_TOPICS=20, alpha=0.1, eta=0.1):\n    # Train the LDA model\n    lda_model = models.LdaModel(\n        corpus=corpus_bow_w_pos_filtered,\n        num_topics=NUM_TOPICS,\n        id2word=dictionary,\n        random_state=1,\n        passes=10,\n        eta=eta,\n        alpha=alpha\n    )\n    \n    # Calculate coherence score\n    coherence_model_lda = CoherenceModel(\n        model=lda_model,\n        texts=tokenized_articles,  # Tokenized documents\n        dictionary=dictionary,\n        coherence='c_v'\n    )\n    coherence_lda = coherence_model_lda.get_coherence()\n    \n    return coherence_lda, lda_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TOPICS=20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_list = ['symmetric',0.3,0.5,0.7]\nbeta_list = ['auto',0.3,0.5,0.7]\n\nfor alpha in alpha_list:\n        for beta in beta_list:\n            coherence_score = calculate_coherence_score(NUM_TOPICS, alpha, beta)\n            print(f\"alpha : {alpha} ; beta : {beta} ; Score : {coherence_score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coherence_score,lda_model= calculate_coherence_score(NUM_TOPICS=20, alpha=\"symmetric\", eta=0.7)\nprint(\"Coherence score is: \",coherence_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_articles_models(article_idx=10):\n    print(dataset[article_idx][:300])\n    print(\"--------------------------\\n\")\n    topics=sorted(ldamodel.get_document_topics(corpus_bow_w_pos_filtered[article_idx]),key=lambda tup:tup[1])[::-1]\n    return topics\ntopics=show_articles_models()\nprint(topics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_topics(article_idx,min_topic_prob):\n    topic_prob_pairs=sorted(ldamodel.get_document_topics(corpus_bow_w_pos_filtered[article_idx],\n                                                         minimum_probability=min_topic_prob),\n                            key=lambda tup:tup[1])[::-1]\n    word_prob_pairs=[ldamodel.show_topic(pair[0]) for pair in topic_prob_pairs]\n    \n    topic_words=[[pair[0] for pair in collection] for collection in word_prob_pairs]\n    data={\n        \"Major Topics\":topic_prob_pairs,\n        \"Topic Words\":topic_words\n    }\n    return pd.DataFrame(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_top_topics(1000,0.12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ldamodel.show_topic(topics[2][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(ldamodel, corpus_bow_w_pos_filtered, dictionary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def render_word_cloud(model,rows,cols,max_words):\n    word_cloud=WordCloud(background_color=\"white\",max_words=max_words,prefer_horizontal=1.0)\n    fig,axes=plt.subplots(rows,cols,figsize=(15,15))\n    \n    for i ,ax in enumerate(axes.flatten()):\n        fig.add_subplot(ax)\n        topic_words=dict(model.show_topic(i))\n        word_cloud.generate_from_frequencies(topic_words)\n        plt.gca().imshow(word_cloud,interpolation=\"bilinear\")\n        plt.gca().set_title(\"Topic {id}\".format(id=i))\n        plt.gca().axis(\"off\")\n    plt.axis(\"off\")\n    plt.savefig(\"file/WordCloud.jpg\")\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"render_word_cloud(ldamodel,4,4,10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_index=similarities.MatrixSimilarity(ldamodel[corpus_bow_w_pos_filtered],num_features=len(dictionary))\n\ndef get_similar_articles(index, model, article_bow, top_n=5, first_m_words=300):\n    \n\n      similar_docs = index[model[article_bow]]\n      top_n_docs = sorted(enumerate(similar_docs), key=lambda item: -item[1])[1:top_n+1]\n  \n      return list(map(lambda entry: (entry[0], entry[1], articles[entry[0]][:first_m_words]), top_n_docs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncoherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized_articles, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncoherence_model_lda = CoherenceModel(model=ldamodel, texts=tokenized_articles, dictionary=dictionary, coherence='u_mass')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_index=0\nprint(dataset[article_index][:snippet_length],\"\\n\")\nget_similar_articles(lda_index,ldamodel,corpus_bow_w_pos_filtered[article_idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_article = \"DEA agent sentenced to 12 years in prison for conspiring with Colombian drug cartel.\"\narticle_tokens=list(map(basic_filter,[nlp(test_article)]))[0]\narticle_bow=dictionary.doc2bow(article_tokens)\nget_similar_articles(lda_index,ldamodel,article_bow)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_model.save('/kaggle/working/file/lda_model.gensim')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Second Datasets for Topic Modelling**\n","metadata":{}},{"cell_type":"code","source":"df_articles=pd.read_csv('/kaggle/input/topic-modeling-for-research-articles/test.csv')\ndf_articles","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:34:54.730429Z","iopub.execute_input":"2024-07-20T07:34:54.731084Z","iopub.status.idle":"2024-07-20T07:34:54.986237Z","shell.execute_reply.started":"2024-07-20T07:34:54.731051Z","shell.execute_reply":"2024-07-20T07:34:54.985194Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_articles.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:34:59.251825Z","iopub.execute_input":"2024-07-20T07:34:59.252315Z","iopub.status.idle":"2024-07-20T07:34:59.340904Z","shell.execute_reply.started":"2024-07-20T07:34:59.252277Z","shell.execute_reply":"2024-07-20T07:34:59.339701Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_articles.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:06.222682Z","iopub.execute_input":"2024-07-20T07:35:06.223678Z","iopub.status.idle":"2024-07-20T07:35:06.234466Z","shell.execute_reply.started":"2024-07-20T07:35:06.223641Z","shell.execute_reply":"2024-07-20T07:35:06.233212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_articles_create=df_articles.drop(columns=[\"TITLE\",\"ID\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:07.498745Z","iopub.execute_input":"2024-07-20T07:35:07.499156Z","iopub.status.idle":"2024-07-20T07:35:07.507729Z","shell.execute_reply.started":"2024-07-20T07:35:07.499125Z","shell.execute_reply":"2024-07-20T07:35:07.506487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_articles_create.tail(2)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:10.969271Z","iopub.execute_input":"2024-07-20T07:35:10.969624Z","iopub.status.idle":"2024-07-20T07:35:10.978986Z","shell.execute_reply.started":"2024-07-20T07:35:10.969596Z","shell.execute_reply":"2024-07-20T07:35:10.977763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"research_articles=list(df_articles_create[\"ABSTRACT\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:12.164334Z","iopub.execute_input":"2024-07-20T07:35:12.164735Z","iopub.status.idle":"2024-07-20T07:35:12.172067Z","shell.execute_reply.started":"2024-07-20T07:35:12.164690Z","shell.execute_reply":"2024-07-20T07:35:12.170938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"research_articles[:10]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:35:16.199198Z","iopub.execute_input":"2024-07-20T07:35:16.199596Z","iopub.status.idle":"2024-07-20T07:35:16.207007Z","shell.execute_reply.started":"2024-07-20T07:35:16.199565Z","shell.execute_reply":"2024-07-20T07:35:16.205851Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# Your custom stop words\ncustom_stop_words = set(STOP_WORDS)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:40:59.214461Z","iopub.execute_input":"2024-07-20T07:40:59.214941Z","iopub.status.idle":"2024-07-20T07:40:59.220768Z","shell.execute_reply.started":"2024-07-20T07:40:59.214902Z","shell.execute_reply":"2024-07-20T07:40:59.219606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def basic_filter(tokenized_doc):\n    return [t.lemma_ for t in tokenized_doc if t.is_alpha and not t.is_punct and not t.is_space and t not in custom_stop_words and t.pos_ in [\"NOUN\",\"VERB\",\"ADJ\"]]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:41:26.800232Z","iopub.execute_input":"2024-07-20T07:41:26.800960Z","iopub.status.idle":"2024-07-20T07:41:26.806436Z","shell.execute_reply.started":"2024-07-20T07:41:26.800924Z","shell.execute_reply":"2024-07-20T07:41:26.805215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_research_articles=list(map(basic_filter,nlp.pipe(research_articles,n_process=4)))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:41:28.139385Z","iopub.execute_input":"2024-07-20T07:41:28.139783Z","iopub.status.idle":"2024-07-20T07:43:08.724701Z","shell.execute_reply.started":"2024-07-20T07:41:28.139752Z","shell.execute_reply":"2024-07-20T07:43:08.723379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndictionary_research_artcles=corpora.Dictionary(tokenized_research_articles)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:44:39.842095Z","iopub.execute_input":"2024-07-20T07:44:39.842524Z","iopub.status.idle":"2024-07-20T07:44:40.922732Z","shell.execute_reply.started":"2024-07-20T07:44:39.842488Z","shell.execute_reply":"2024-07-20T07:44:40.921443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_token_research=\"science\"\nprint(f\"Id for \\'{sample_token_research}\\' token: {dictionary_research_artcles.token2id[sample_token_research]}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:44:54.592363Z","iopub.execute_input":"2024-07-20T07:44:54.593030Z","iopub.status.idle":"2024-07-20T07:44:54.598334Z","shell.execute_reply.started":"2024-07-20T07:44:54.592996Z","shell.execute_reply":"2024-07-20T07:44:54.597126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncorpus_bow_research_articles=[dictionary_research_artcles.doc2bow(article) for article in tokenized_research_articles]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:44:58.415504Z","iopub.execute_input":"2024-07-20T07:44:58.416595Z","iopub.status.idle":"2024-07-20T07:44:59.018017Z","shell.execute_reply.started":"2024-07-20T07:44:58.416557Z","shell.execute_reply":"2024-07-20T07:44:59.016977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(corpus_bow_research_articles))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:45:08.610862Z","iopub.execute_input":"2024-07-20T07:45:08.611701Z","iopub.status.idle":"2024-07-20T07:45:08.616832Z","shell.execute_reply.started":"2024-07-20T07:45:08.611639Z","shell.execute_reply":"2024-07-20T07:45:08.615633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary_research_artcles.filter_extremes(no_below=5,no_above=0.6)\ncorpus_bow_research_articles_filtered=[dictionary_research_artcles.doc2bow(article) for article in tokenized_research_articles]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:45:13.790468Z","iopub.execute_input":"2024-07-20T07:45:13.790899Z","iopub.status.idle":"2024-07-20T07:45:14.809142Z","shell.execute_reply.started":"2024-07-20T07:45:13.790865Z","shell.execute_reply":"2024-07-20T07:45:14.807950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_perplexity(corpus_bow_w_pos_filtered, dictionary, num_topics_list):\n    perplexities = []\n    for num_topics in num_topics_list:\n        lda_model = models.LdaModel(corpus=corpus_bow_w_pos_filtered,\n                        num_topics=num_topics,\n                        id2word=dictionary,\n                        random_state=1,\n                        passes=10,\n                        eta=0.1,\n                        alpha=0.1)\n        perplexity = lda_model.log_perplexity(corpus_bow_w_pos_filtered)\n        perplexities.append(perplexity)\n        print(f'Number of topics: {num_topics}, Perplexity: {perplexity}')\n    return perplexities\n\n# Example usage\nnum_topics_list = [3, 6, 9, 12, 15]\nperplexities = evaluate_perplexity(corpus_bow_research_articles_filtered, dictionary_research_artcles, num_topics_list)\nbest_num_topics = num_topics_list[np.argmin(perplexities)]\nprint(f'Best number of topics based on perplexity: {best_num_topics}')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:45:22.210999Z","iopub.execute_input":"2024-07-20T07:45:22.211397Z","iopub.status.idle":"2024-07-20T07:52:15.075760Z","shell.execute_reply.started":"2024-07-20T07:45:22.211365Z","shell.execute_reply":"2024-07-20T07:52:15.074616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models.coherencemodel import CoherenceModel\n\ndef evaluate_topic_models(corpus_bow_w_pos_filtered, dictionary, num_topics_list):\n    coherence_scores = []\n    for num_topics in num_topics_list:\n        lda_model = models.LdaModel(corpus_bow_w_pos_filtered, num_topics=num_topics, id2word=dictionary, passes=15)\n        coherence_model = CoherenceModel(model=lda_model, texts=tokenized_research_articles, dictionary=dictionary, coherence='c_v')\n        coherence_score = coherence_model.get_coherence()\n        coherence_scores.append(coherence_score)\n        print(f'Number of topics: {num_topics}, Coherence Score: {coherence_score}')\n    return coherence_scores\n\nnum_topics_list = [3, 6, 9, 12, 15]\ncoherence_scores = evaluate_topic_models(corpus_bow_research_articles_filtered, dictionary_research_artcles, num_topics_list)\nbest_num_topics = num_topics_list[np.argmax(coherence_scores)]\nprint(f'Best number of topics: {best_num_topics}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T07:52:15.078024Z","iopub.execute_input":"2024-07-20T07:52:15.078969Z","iopub.status.idle":"2024-07-20T08:01:31.359229Z","shell.execute_reply.started":"2024-07-20T07:52:15.078924Z","shell.execute_reply":"2024-07-20T08:01:31.358005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_topics_list = [30, 27, 18, 21, 24]\ncoherence_scores = evaluate_topic_models(corpus_bow_research_articles_filtered, dictionary_research_artcles, num_topics_list)\nbest_num_topics = num_topics_list[np.argmax(coherence_scores)]\nprint(f'Best number of topics: {best_num_topics}')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:02:46.735925Z","iopub.execute_input":"2024-07-20T08:02:46.736298Z","iopub.status.idle":"2024-07-20T08:13:20.238045Z","shell.execute_reply.started":"2024-07-20T08:02:46.736271Z","shell.execute_reply":"2024-07-20T08:13:20.236881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import HdpModel\n\n\nhdp_model = HdpModel(corpus_bow_research_articles_filtered, id2word=dictionary_research_artcles)\n\nfor topic_id, topic in hdp_model.show_topics(formatted=False):\n    print(f\"Topic {topic_id}:\")\n    print(\" \".join([word for word, _ in topic]))\n    \n\ncoherence_model = CoherenceModel(model=hdp_model, texts=tokenized_research_articles, dictionary=dictionary_research_artcles, coherence='c_v')\ncoherence_score = coherence_model.get_coherence()\nprint(f'Coherence Score: {coherence_score}')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:15:26.681571Z","iopub.execute_input":"2024-07-20T08:15:26.682017Z","iopub.status.idle":"2024-07-20T08:17:13.039150Z","shell.execute_reply.started":"2024-07-20T08:15:26.681979Z","shell.execute_reply":"2024-07-20T08:17:13.038128Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyLDAvis.gensim\npyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(hdp_model, corpus_bow_research_articles_filtered, dictionary_research_artcles)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:32:22.413682Z","iopub.execute_input":"2024-07-20T08:32:22.414549Z","iopub.status.idle":"2024-07-20T08:33:53.594833Z","shell.execute_reply.started":"2024-07-20T08:32:22.414503Z","shell.execute_reply":"2024-07-20T08:33:53.593499Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_coherence_score(NUM_TOPICS=6, alpha=0.1, eta=0.1):\n    # Train the LDA model\n    lda_model = models.LdaModel(\n        corpus=corpus_bow_research_articles_filtered,\n        num_topics=NUM_TOPICS,\n        id2word=dictionary_research_artcles,\n        random_state=1,\n        passes=10,\n        eta=eta,\n        alpha=alpha\n    )\n    \n    # Calculate coherence score\n    coherence_model_lda = CoherenceModel(\n        model=lda_model,\n        texts=tokenized_research_articles,  # Tokenized documents\n        dictionary=dictionary_research_artcles,\n        coherence='c_v'\n    )\n    coherence_lda = coherence_model_lda.get_coherence()\n    \n    return coherence_lda, lda_model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:55:36.979989Z","iopub.execute_input":"2024-07-20T08:55:36.980923Z","iopub.status.idle":"2024-07-20T08:55:36.988075Z","shell.execute_reply.started":"2024-07-20T08:55:36.980881Z","shell.execute_reply":"2024-07-20T08:55:36.986889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TOPICS=6","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:55:37.347660Z","iopub.execute_input":"2024-07-20T08:55:37.348096Z","iopub.status.idle":"2024-07-20T08:55:37.353317Z","shell.execute_reply.started":"2024-07-20T08:55:37.348063Z","shell.execute_reply":"2024-07-20T08:55:37.352192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_list = ['symmetric',0.3,0.5,0.7]\nbeta_list = ['auto',0.3,0.5,0.7]\n\nfor alpha in alpha_list:\n        for beta in beta_list:\n            coherence_score,lda_model = calculate_coherence_score(NUM_TOPICS, alpha, beta)\n            print(f\"alpha : {alpha} ; beta : {beta} ; Score : {coherence_score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T08:58:53.499357Z","iopub.execute_input":"2024-07-20T08:58:53.499781Z","iopub.status.idle":"2024-07-20T09:20:29.422532Z","shell.execute_reply.started":"2024-07-20T08:58:53.499746Z","shell.execute_reply":"2024-07-20T09:20:29.421126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coherence_score,lda_model= calculate_coherence_score(NUM_TOPICS=6, alpha=0.7, eta=0.7)\nprint(\"Coherence score is: \",coherence_score)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:20:43.914983Z","iopub.execute_input":"2024-07-20T09:20:43.915395Z","iopub.status.idle":"2024-07-20T09:22:04.066168Z","shell.execute_reply.started":"2024-07-20T09:20:43.915354Z","shell.execute_reply":"2024-07-20T09:22:04.065027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyLDAvis.gensim\npyLDAvis.enable_notebook()\npyLDAvis.gensim.prepare(lda_model, corpus_bow_research_articles_filtered, dictionary_research_artcles)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:22:04.068127Z","iopub.execute_input":"2024-07-20T09:22:04.068452Z","iopub.status.idle":"2024-07-20T09:22:11.907902Z","shell.execute_reply.started":"2024-07-20T09:22:04.068424Z","shell.execute_reply":"2024-07-20T09:22:11.906777Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_articles_models(article_idx=10):\n    print(research_articles[article_idx][:300])\n    print(\"--------------------------\\n\")\n    topics=sorted(lda_model.get_document_topics(corpus_bow_research_articles_filtered[article_idx]),key=lambda tup:tup[1])[::-1]\n    return topics\ntopics=show_articles_models()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:24:38.706514Z","iopub.execute_input":"2024-07-20T09:24:38.706971Z","iopub.status.idle":"2024-07-20T09:24:38.716869Z","shell.execute_reply.started":"2024-07-20T09:24:38.706938Z","shell.execute_reply":"2024-07-20T09:24:38.715700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for pair in topics:\n    print(sorted(lda_model.show_topic(pair[0]),key=lambda tup:tup[1])[::-1])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:25:23.687897Z","iopub.execute_input":"2024-07-20T09:25:23.688959Z","iopub.status.idle":"2024-07-20T09:25:23.696951Z","shell.execute_reply.started":"2024-07-20T09:25:23.688923Z","shell.execute_reply":"2024-07-20T09:25:23.695783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs(\"file\",exist_ok=True)\ndef render_word_cloud(model,rows,cols,max_words):\n    word_cloud=WordCloud(background_color=\"white\",max_words=max_words,prefer_horizontal=1.0)\n    fig,axes=plt.subplots(rows,cols,figsize=(15,15))\n    \n    for i ,ax in enumerate(axes.flatten()):\n        fig.add_subplot(ax)\n        topic_words=dict(model.show_topic(i))\n        word_cloud.generate_from_frequencies(topic_words)\n        plt.gca().imshow(word_cloud,interpolation=\"bilinear\")\n        plt.gca().set_title(\"Topic {id}\".format(id=i))\n        plt.gca().axis(\"off\")\n    plt.axis(\"off\")\n    plt.savefig(\"file/WordCloud.jpg\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:26:00.779270Z","iopub.execute_input":"2024-07-20T09:26:00.779670Z","iopub.status.idle":"2024-07-20T09:26:00.789272Z","shell.execute_reply.started":"2024-07-20T09:26:00.779641Z","shell.execute_reply":"2024-07-20T09:26:00.788027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_topics(article_idx,min_topic_prob=0.25):\n    topic_prob_pairs=sorted(lda_model.get_document_topics(corpus_bow_research_articles_filtered[article_idx],\n                                                         minimum_probability=min_topic_prob),\n                            key=lambda tup:tup[1])[::-1]\n    word_prob_pairs=[lda_model.show_topic(pair[0]) for pair in topic_prob_pairs]\n    \n    topic_words=[[pair[0] for pair in collection] for collection in word_prob_pairs]\n    data={\n        \"Major Topics\":topic_prob_pairs,\n        \"Topic Words\":topic_words\n    }\n    return pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:27:29.786900Z","iopub.execute_input":"2024-07-20T09:27:29.787290Z","iopub.status.idle":"2024-07-20T09:27:29.794827Z","shell.execute_reply.started":"2024-07-20T09:27:29.787261Z","shell.execute_reply":"2024-07-20T09:27:29.793685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"max_colwidth\",600)\nsnippet_length=300\nmin_topic_prob=0.30\narticle_idx=1\nprint(research_articles[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:27:53.418332Z","iopub.execute_input":"2024-07-20T09:27:53.418749Z","iopub.status.idle":"2024-07-20T09:27:53.438395Z","shell.execute_reply.started":"2024-07-20T09:27:53.418714Z","shell.execute_reply":"2024-07-20T09:27:53.437286Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_idx=78\nprint(research_articles[article_idx][:snippet_length])\nget_top_topics(article_idx,min_topic_prob)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:28:07.054422Z","iopub.execute_input":"2024-07-20T09:28:07.055161Z","iopub.status.idle":"2024-07-20T09:28:07.074783Z","shell.execute_reply.started":"2024-07-20T09:28:07.055125Z","shell.execute_reply":"2024-07-20T09:28:07.073770Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"render_word_cloud(lda_model,2,2,10)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:28:49.293692Z","iopub.execute_input":"2024-07-20T09:28:49.294938Z","iopub.status.idle":"2024-07-20T09:28:50.600542Z","shell.execute_reply.started":"2024-07-20T09:28:49.294891Z","shell.execute_reply":"2024-07-20T09:28:50.599364Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_index=similarities.MatrixSimilarity(lda_model[corpus_bow_research_articles_filtered],num_features=len(dictionary_research_artcles))\ndef get_similar_articles(index, model, article_bow, top_n=5, first_m_words=300):\n    \n\n      similar_docs = index[model[article_bow]]\n      top_n_docs = sorted(enumerate(similar_docs), key=lambda item: -item[1])[1:top_n+1]\n  \n      return list(map(lambda entry: (entry[0], entry[1], research_articles[entry[0]][:first_m_words]), top_n_docs))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:34:37.761396Z","iopub.execute_input":"2024-07-20T09:34:37.761774Z","iopub.status.idle":"2024-07-20T09:34:45.101082Z","shell.execute_reply.started":"2024-07-20T09:34:37.761746Z","shell.execute_reply":"2024-07-20T09:34:45.100115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_index","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:34:45.103070Z","iopub.execute_input":"2024-07-20T09:34:45.103398Z","iopub.status.idle":"2024-07-20T09:34:45.110730Z","shell.execute_reply.started":"2024-07-20T09:34:45.103370Z","shell.execute_reply":"2024-07-20T09:34:45.109616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_index=0\nprint(research_articles[article_index][:snippet_length],\"\\n\")\nget_similar_articles(lda_index,lda_model,corpus_bow_research_articles_filtered[article_idx])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:34:45.112103Z","iopub.execute_input":"2024-07-20T09:34:45.112438Z","iopub.status.idle":"2024-07-20T09:34:45.161866Z","shell.execute_reply.started":"2024-07-20T09:34:45.112409Z","shell.execute_reply":"2024-07-20T09:34:45.160626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_article = \"We study the proportional chore division problem where a protocol wants to\\ndivide an undesirable object, called chore, among $n$ different players. The\\ngoal is to find an allocation such that the cost of the chore assigned to each\\nplayer be at most $1/n$ of the total cost. This problem is the dual\"\narticle_tokens=list(map(basic_filter,[nlp(test_article)]))[0]\narticle_bow=dictionary_research_artcles.doc2bow(article_tokens)\nget_similar_articles(lda_index,lda_model,article_bow)\n# list(map(basic_filter,nlp.pipe(research_articles,n_process=4)))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:38:56.676648Z","iopub.execute_input":"2024-07-20T09:38:56.677027Z","iopub.status.idle":"2024-07-20T09:38:56.733065Z","shell.execute_reply.started":"2024-07-20T09:38:56.677000Z","shell.execute_reply":"2024-07-20T09:38:56.731875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda_model.save('/kaggle/working/file/lda_model_research_articles.gensim')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:39:42.133966Z","iopub.execute_input":"2024-07-20T09:39:42.134982Z","iopub.status.idle":"2024-07-20T09:39:42.147950Z","shell.execute_reply.started":"2024-07-20T09:39:42.134945Z","shell.execute_reply":"2024-07-20T09:39:42.146522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_topics = 6\n\nfor i in range(num_topics):\n    plt.figure()\n    # Extracting the words and their weights for the ith topic\n    topic_words = {word: value for word, value in lda_model.show_topic(i, topn=50)}\n    \n    # Generating the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(topic_words)\n    \n    # Display the word cloud using matplotlib\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(f' \\n\\nTopic #{i+1}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T09:42:06.654393Z","iopub.execute_input":"2024-07-20T09:42:06.654865Z","iopub.status.idle":"2024-07-20T09:42:10.420073Z","shell.execute_reply.started":"2024-07-20T09:42:06.654824Z","shell.execute_reply":"2024-07-20T09:42:10.419039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}